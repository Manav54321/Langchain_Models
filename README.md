# ğŸ§  LangChain Models Component

This project explores the different types of models supported by [LangChain](https://www.langchain.com/) and how to use them effectively for language-based tasks such as generation, embeddings, and semantic search.

Whether you're working with OpenAI, HuggingFace, or your own local models â€” this repo demonstrates how to integrate them with LangChain in a clean and modular way.

---

## ğŸ“š What Are "Models" in LangChain?

LangChain uses **models** for:

- **Language generation** (e.g., ChatGPT, Claude)
- **Embeddings** (e.g., for similarity search, clustering, RAG pipelines)

Two main categories:
1. **Language Models (LLMs & Chat Models)**
2. **Embedding Models**

---

## ğŸ§© Types of Models in LangChain

```mermaid
graph TD
    A[Models] --> B[Language Models]
    A --> C[Embedding Models]
    B --> B1[LLMs]
    B --> B2[Chat Models]
````

---

## ğŸ—£ï¸ Language Models

### ğŸ” LLMs vs Chat Models

| Feature         | LLMs                 | Chat Models                   |
| --------------- | -------------------- | ----------------------------- |
| Input Format    | Single prompt string | Chat-style (list of messages) |
| Usage           | Completions          | Multi-turn conversations      |
| Example         | `text-davinci-003`   | `gpt-3.5-turbo`, `claude-v1`  |
| LangChain Class | `LLM`                | `ChatModel`                   |

---

### ğŸ›‘ Closed-source Language Models

| Provider  | Models                             |
| --------- | ---------------------------------- |
| OpenAI    | `gpt-3.5-turbo`, `gpt-4`           |
| Anthropic | `claude-1`, `claude-2`, `claude-3` |
| Google    | `gemini-pro`, `gemini-1.5-pro`     |

Accessed via API keys.

---

### ğŸŒ Open-source Language Models

| Source      | Examples                                                          |
| ----------- | ----------------------------------------------------------------- |
| HuggingFace | `tiiuae/falcon-7b-instruct`, `mistralai/Mistral-7B-Instruct-v0.1` |
| Others      | LLama 2, Zephyr, Deepseek, OpenChat                               |

**Usage:**

* HuggingFace Inference API
* Run locally using `transformers`, `AutoModel`, or `text-generation-webui`

Example:

```python
from transformers import pipeline
pipe = pipeline("text-generation", model="tiiuae/falcon-7b-instruct")
```

---

## ğŸ§¬ Embedding Models

Used to convert text into numerical vectors for:

* Semantic search
* Question answering
* Text similarity
* RAG pipelines

---

### ğŸ›‘ Closed-source Embedding Models

| Provider | Model Name               |
| -------- | ------------------------ |
| OpenAI   | `text-embedding-ada-002` |
| Gemini   | Gemini Embed             |
| Cohere   | Embed-v3                 |

---

### ğŸŒ Open-source Embedding Models

| Source      | Examples                                                           |
| ----------- | ------------------------------------------------------------------ |
| HuggingFace | `sentence-transformers/all-MiniLM-L6-v2`, `BAAI/bge-small-en-v1.5` |
| Usage       | `HuggingFaceEmbeddings` class in LangChain                         |

Example:

```python
from langchain.embeddings import HuggingFaceEmbeddings

model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
```

---

## ğŸŒ¡ï¸ Temperature (in Language Models)

> Controls randomness and creativity in generation.

| Temperature | Behavior         |
| ----------- | ---------------- |
| 0           | Deterministic    |
| 0.7         | Balanced         |
| 1.0         | More creative    |
| >1.0        | Often incoherent |

Higher temp â†’ more randomness.
Lower temp â†’ more focused and repetitive.

---

## ğŸ› ï¸ Mini Project: Semantic Search

A simple retrieval-based pipeline using LangChain.

### ğŸ” Objective

Given a user query, retrieve the most relevant document chunks using vector embeddings.

### ğŸ§° Stack Used

* `langchain`
* `sentence-transformers`
* `FAISS` vector DB

### âœ… Pipeline

1. Load and split text documents
2. Convert them to embeddings
3. Store in FAISS
4. Accept user query â†’ embed â†’ compare via cosine similarity â†’ retrieve top matches

### ğŸš€ Run the Demo

```bash
python semantic_search_demo.py
```

---

## ğŸ“ Project Structure

```
langchain_models/
â”‚
â”œâ”€â”€ language_models/
â”‚   â”œâ”€â”€ openai_chat.py              # OpenAI Chat Models
â”‚   â”œâ”€â”€ huggingface_local.py        # Local HF Model via transformers
â”‚
â”œâ”€â”€ embedding_models/
â”‚   â”œâ”€â”€ openai_embedding.py
â”‚   â”œâ”€â”€ huggingface_embedding.py
â”‚
â”œâ”€â”€ semantic_search_demo.py         # End-to-end semantic search pipeline
â”‚
â””â”€â”€ README.md
```

---

## ğŸ’¡ Future Additions

* Performance benchmark across models
* Add Gemini + Claude integration
* LangSmith Tracing support
* RAG pipeline (retrieval-augmented generation)

---

## ğŸ¤ Contributing

Pull requests are welcome. If you find issues or want to improve code/docs, feel free to submit a PR or open an issue.

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Author

Made with â¤ï¸ by **[Manav Desai](https://github.com/manavdesai)**
AI Engineer | NLP & Agentic AI Enthusiast
